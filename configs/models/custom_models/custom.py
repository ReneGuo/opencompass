from opencompass.models import HuggingFaceCausalLM, InternLM, HuggingFace

# Please note that we have specified the revision here. Recently (on 20230827),
# during our evaluations, we found that the newer revision models have a drop
# of more than 5 points on datasets like GaokaoBench / mbpp.
# We are not yet sure whether this drop is due to incorrect logic in OpenCompass
# calling qwen or some other reasons. We would like to highlight this.

models = [
    dict(
        type=HuggingFaceCausalLM,
        abbr="qwen-7b-hf",
        path="/mnt/turbocfs/evaluation_pretrain/models/sota/qwen-7b",
        tokenizer_path="/mnt/turbocfs/evaluation_pretrain/models/sota/qwen-7b",
        tokenizer_kwargs=dict(
            padding_side="left",
            truncation_side="left",
            trust_remote_code=True,
            use_fast=False,
            revision="39fc5fdcb95c8c367bbdb3bfc0db71d96266de09",
        ),
        pad_token_id=151643,
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        model_kwargs=dict(
            device_map="auto",
            trust_remote_code=True,
            revision="39fc5fdcb95c8c367bbdb3bfc0db71d96266de09",
        ),
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        type=HuggingFaceCausalLM,
        abbr="internlm-7b-hf",
        path="/mnt/turbocfs/evaluation_pretrain/models/sota/internlm-7b",
        tokenizer_path="/mnt/turbocfs/evaluation_pretrain/models/sota/internlm-7b",
        tokenizer_kwargs=dict(
            padding_side="left",
            truncation_side="left",
            use_fast=False,
            trust_remote_code=True,
        ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        model_kwargs=dict(trust_remote_code=True, device_map="auto"),
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        type=HuggingFaceCausalLM,
        abbr="internlm-chat-7b-hf",
        path="/mnt/turbocfs/evaluation_pretrain/models/sota/internlm-chat-7b",
        tokenizer_path="/mnt/turbocfs/evaluation_pretrain/models/sota/internlm-chat-7b",
        tokenizer_kwargs=dict(
            padding_side="left",
            truncation_side="left",
            use_fast=False,
            trust_remote_code=True,
            revision="1a6328795c6e207904e1eb58177e03ad24ae06f3",
        ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        meta_template=dict(
            round=[
                dict(role="HUMAN", begin="<|User|>:", end="<eoh>\n"),
                dict(role="BOT", begin="<|Bot|>:", end="<eoa>\n", generate=True),
            ],
        ),
        model_kwargs=dict(
            trust_remote_code=True,
            device_map="auto",
            revision="1a6328795c6e207904e1eb58177e03ad24ae06f3",
        ),
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        type=HuggingFaceCausalLM,
        abbr="falcon-7b-hf",
        path="/mnt/turbocfs/evaluation_pretrain/models/sota/falcon-7b",
        tokenizer_path="/mnt/turbocfs/evaluation_pretrain/models/sota/falcon-7b",
        tokenizer_kwargs=dict(
            padding_side="left",
            truncation_side="left",
            trust_remote_code=True,
        ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        model_kwargs=dict(
            trust_remote_code=True,
            device_map="auto",
            revision="2f5c3cd4eace6be6c0f12981f377fb35e5bf6ee5",
        ),
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        type=HuggingFace,
        abbr="chatglm2-6b-hf",
        path="/mnt/turbocfs/evaluation_pretrain/models/sota/chatglm2-6b",
        tokenizer_path="/mnt/turbocfs/evaluation_pretrain/models/sota/chatglm2-6b",
        tokenizer_kwargs=dict(
            padding_side="left",
            truncation_side="left",
            trust_remote_code=True,
        ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        model_kwargs=dict(
            trust_remote_code=True,
            device_map="auto",
            revision="a6d54fac46dff2db65d53416c207a4485ca6bd40",
        ),
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        type=HuggingFaceCausalLM,
        abbr="baichuan2-7b-base-hf",
        path="/mnt/turbocfs/evaluation_pretrain/models/sota/Baichuan2-7B-Base",
        tokenizer_path="/mnt/turbocfs/evaluation_pretrain/models/sota/Baichuan2-7B-Base",
        tokenizer_kwargs=dict(
            padding_side="left",
            truncation_side="left",
            trust_remote_code=True,
            use_fast=False,
        ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        model_kwargs=dict(device_map="auto", trust_remote_code=True),
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        type=HuggingFaceCausalLM,
        abbr="baichuan2-7b-chat-hf",
        path="/mnt/turbocfs/evaluation_pretrain/models/sota/Baichuan2-7B-Chat",
        tokenizer_path="/mnt/turbocfs/evaluation_pretrain/models/sota/Baichuan2-7B-Chat",
        tokenizer_kwargs=dict(
            padding_side="left",
            truncation_side="left",
            trust_remote_code=True,
            use_fast=False,
        ),
        meta_template=dict(
            round=[
                dict(role="HUMAN", begin="<reserved_106>"),
                dict(role="BOT", begin="<reserved_107>", generate=True),
            ],
        ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        model_kwargs=dict(device_map="auto", trust_remote_code=True),
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
    dict(
        type=HuggingFaceCausalLM,
        abbr="baichuan-7b-hf",
        path="/mnt/turbocfs/evaluation_pretrain/models/sota/baichuan7b",
        tokenizer_path="/mnt/turbocfs/evaluation_pretrain/models/sota/baichuan7b",
        tokenizer_kwargs=dict(
            padding_side="left",
            truncation_side="left",
            trust_remote_code=True,
            use_fast=False,
        ),
        max_out_len=100,
        max_seq_len=2048,
        batch_size=8,
        model_kwargs=dict(device_map="auto", trust_remote_code=True),
        run_cfg=dict(num_gpus=1, num_procs=1),
    ),
]
